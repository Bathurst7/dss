{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encode(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by encoding categorical variables before splitting into training and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the full dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - df_encoded: The DataFrame with categorical columns encoded.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Label Encoding for ordinal categorical variables or One-Hot Encoding for nominal ones\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        # If the column is a categorical feature, apply Label Encoding or One-Hot Encoding\n",
    "        df_encoded[col] = df_encoded[col].astype(str)  # Ensure string type for encoding\n",
    "        \n",
    "        # Apply Label Encoding (you can use OneHotEncoder if needed for non-ordinal data)\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_encoded[col] = label_encoder.fit_transform(df_encoded[col])\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = label_encode(df)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, year_split=2022):\n",
    "    \"\"\"\n",
    "    Split the data into training and test sets based on the year column.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the full dataset.\n",
    "    - target_column: The name of the target variable column.\n",
    "    - year_split: The year to split on (default is 2022).\n",
    "    \n",
    "    Returns:\n",
    "    - train_data: DataFrame containing the training data.\n",
    "    - test_data: DataFrame containing the test data.\n",
    "    \"\"\"\n",
    "    train_data = df[df['Year'] <= year_split]\n",
    "    test_data = df[df['Year'] > year_split]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def train_gradient_boosting(train_data, target_column, feature_columns, n_splits=5, scoring='neg_root_mean_squared_error'):\n",
    "    \"\"\"\n",
    "    Train a Random Forest model using GridSearchCV with time-series cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: DataFrame containing the training data.\n",
    "    - target_column: The name of the target variable column (dependent variable).\n",
    "    - feature_columns: List of column names to be used as features (independent variables).\n",
    "    - n_splits: Number of splits for time-series cross-validation (default is 5).\n",
    "    - scoring: The scoring metric for GridSearchCV (default is RMSE).\n",
    "    \n",
    "    Returns:\n",
    "    - best_model: The best trained model after hyperparameter tuning.\n",
    "    - best_params: The best set of hyperparameters found.\n",
    "    - r2_train: R² score on the training set.\n",
    "    \"\"\"\n",
    "    param_grid = {  \n",
    "        'learning_rate': [0.05, 0.2, 0.1], \n",
    "        \"min_samples_split\":[2, 3, 5],\n",
    "        \"max_depth\": [ 3, 4, 5],\n",
    "        \"min_samples_leaf\": [1, 3, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0], \n",
    "        'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "    \n",
    "    X_train = train_data[feature_columns]\n",
    "    y_train = train_data[target_column]\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(random_state=42)\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=tscv, scoring=scoring, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Calculate R² on the training data\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    return best_model, best_params, r2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_model(model, test_data, target_column, feature_columns):\n",
    "    \"\"\"\n",
    "    Evaluate the model using RMSE and R² on the test data.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model to be evaluated.\n",
    "    - test_data: DataFrame containing the test data.\n",
    "    - target_column: The name of the target variable column.\n",
    "    - feature_columns: List of column names to be used as features.\n",
    "    \n",
    "    Returns:\n",
    "    - rmse: Root Mean Squared Error (RMSE) on the test set.\n",
    "    - r2: R² score on the test set.\n",
    "    \"\"\"\n",
    "    X_test = test_data[feature_columns]\n",
    "    y_test = test_data[target_column]\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    # Calculate R² score\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = split_data(df_encoded)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: \n",
    "feature_columns = [col for col in df.columns if col != \"TSR\"]\n",
    "\n",
    "# Step 3: Train the model with GridSearchCV\n",
    "best_model, best_params, r2_train = train_gradient_boosting(train_data, target_column=\"TSR\", feature_columns=feature_columns)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "rmse = evaluate_model(best_model, test_data, target_column=\"TSR\", feature_columns=feature_columns)\n",
    "\n",
    "# Output the results\n",
    "print(f\"\\n Best Hyperparameters: {best_params}\")\n",
    "print(f\"\\n R2 on Train-set: {r2_train}\")\n",
    "print(f\"\\n Root Mean Squared Error (RMSE) on Test Set: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def dump_model(best_model, model_path):\n",
    "   joblib.dump(best_model, model_path)\n",
    "\n",
    "model_path = \"../model_folder/xgb.joblib\"\n",
    "dump_model(best_model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
